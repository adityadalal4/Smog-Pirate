{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4b99cea",
   "metadata": {},
   "source": [
    "# THE PROBLEM\n",
    "\n",
    "1. In cities like Delhi, staying out could be equivalent to smoking 50 cigarettes. This problem is because of smog and air pollution. \n",
    "2. Air pollution is the single biggest killer in the world, with some pollutants reducing avg. global life expectancy by 2.2 years. \n",
    "3. There are >5 million deaths from smog a year. \n",
    "4. Global economy lost USD 29 trillion in 2018 according to the World Economic Forum because of air pollution.\n",
    "\n",
    "What people do not understand is that this problem could easily be ended if some international laws can be followed. These mainly include cap and trade schemes for emissions. These are called ETS by the United Nations and are used by many countries in the world. However, what does not allow this to work is a very complicated problem - the problem of tracking pollutants. If a factory pollutes, it is very difficult to track the pollutants back to them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74b0ae3",
   "metadata": {},
   "source": [
    "# MY SOLUTION: SMOG-PIRATE\n",
    "\n",
    "Smog-Pirate is an inventive, data-driven solution to the above problem. First, I studied years of weather and Air pollution data and found correlations between some factors. Then, using multiple regression and adjusting the number of factors, I was able to forecast AQI (Air Quality Index) by >97% efficiency. I started with 17 inputs and ended with 4. I evaluated and \n",
    "\n",
    "I compare the AQI to the actual AQI and if it is much larger, I track the pollutants to diffferent factories based on wind velocities in the last day.\n",
    "\n",
    "There are many complex steps that I had to go through before making this project. The first was to scrape the web for data for weather and live AQI. I did this through Beautiful Soup 4 and requests.\n",
    "\n",
    "Then, I tried to make a novel algorithm for tracking pollutants, and it worked really well. I changed the wind velocity from the last day to vectors and added them to find coordinates. I then referenced known coordinates of factories to give a list of polluters. I also had to use an ipinfo.io API for finding my current coordinates.\n",
    "\n",
    "I then compared AQI's and prescribed a certain penalty to polluters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d55385",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0521c23f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc3e922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30daf4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WNW 17 km/h\n",
      "WNW 19 km/h\n",
      "WNW 19 km/h\n",
      "WNW 20 km/h\n",
      "WNW 18 km/h\n",
      "NW 14 km/h\n",
      "WNW 13 km/h\n",
      "WNW 12 km/h\n",
      "WNW 12 km/h\n",
      "NW 12 km/h\n",
      "WNW 12 km/h\n",
      "WNW 13 km/h\n",
      "WNW 13 km/h\n",
      "WNW 13 km/h\n",
      "WNW 14 km/h\n",
      "WNW 15 km/h\n",
      "WNW 15 km/h\n",
      "WNW 15 km/h\n",
      "WNW 17 km/h\n",
      "WNW 18 km/h\n",
      "WNW 20 km/h\n",
      "WNW 23 km/h\n",
      "WNW 24 km/h\n",
      "WNW 25 km/h\n",
      "WNW 26 km/h\n",
      "WNW 26 km/h\n",
      "WNW 26 km/h\n",
      "WNW 24 km/h\n",
      "WNW 21 km/h\n",
      "WNW 18 km/h\n",
      "WNW 16 km/h\n",
      "WNW 15 km/h\n",
      "WNW 15 km/h\n",
      "WNW 15 km/h\n",
      "WNW 14 km/h\n",
      "WNW 14 km/h\n",
      "WNW 14 km/h\n",
      "WNW 13 km/h\n",
      "WNW 13 km/h\n",
      "WNW 13 km/h\n",
      "WNW 13 km/h\n",
      "WNW 13 km/h\n",
      "WNW 13 km/h\n",
      "WNW 15 km/h\n",
      "WNW 16 km/h\n",
      "WNW 17 km/h\n",
      "WNW 17 km/h\n",
      "WNW 18 km/h\n",
      "25.0\n",
      "1017.3\n",
      "Hazardous\n",
      "186.0\n",
      "211.35718980985735\n",
      "No penalty required\n"
     ]
    }
   ],
   "source": [
    "#Importing required libraries\n",
    "import json\n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import pandas\n",
    "\n",
    "industry_coords=[['A',34,-84],['A1',0,0],['A-1',34,-84]]\n",
    "industry_coords_copy=industry_coords\n",
    "a=[]\n",
    "a0=[]\n",
    "\n",
    "#Data from web-scraping starts\n",
    "\n",
    "#Finding wind speeds for last day for tracking pollutants\n",
    "page = requests.get('https://weather.com/en-IN/weather/hourbyhour/l/cc76c08b470b5ddd6e64efd9ce8f256542cfed4ba52f6c00a30a74da519cd070')\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "blog=soup.findAll('span',attrs={\"class\":\"Wind--windWrapper--3Ly7c undefined\"})\n",
    "\n",
    "for title in blog:\n",
    "    k=title.text\n",
    "    a.append(k.split(' ')[0])\n",
    "    a0.append(float(k.split(' ')[1]))\n",
    "    print(k)\n",
    "\n",
    "#Finding Humidity\n",
    "page = requests.get('https://weather.com/en-IN/weather/today/l/cc76c08b470b5ddd6e64efd9ce8f256542cfed4ba52f6c00a30a74da519cd070')\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "blog=soup.findAll('span',attrs={\"data-testid\":\"PercentageValue\"})\n",
    "for title in blog:\n",
    "    k=title.text\n",
    "avg3=float(k.replace(\"%\",\"\"))   \n",
    "print(avg3)\n",
    "\n",
    "#Finding Dew Point\n",
    "blog=soup.findAll('span',attrs={\"data-testid\":\"TemperatureValue\"})\n",
    "i=0\n",
    "for title in blog:\n",
    "    k=title.text\n",
    "    if(i>=10):\n",
    "        break\n",
    "    i=i+1\n",
    "avg2=float(k.replace(\"°\",\"\"))\n",
    "\n",
    "#Finding avg. temp\n",
    "blog=soup.findAll('span',attrs={\"data-testid\":\"TemperatureValue\"})\n",
    "i=0\n",
    "avg1=0\n",
    "for title in blog:\n",
    "    k=title.text\n",
    "    if(i==1 or i==2):\n",
    "        avg1=avg1+float(k.replace(\"°\",\"\"))\n",
    "    i=i+1\n",
    "avg1=avg1/2\n",
    "\n",
    "#Finding Pressure\n",
    "blog=soup.findAll('span',attrs={\"data-testid\":\"PressureValue\"})\n",
    "i=0\n",
    "for title in blog:\n",
    "    k=title.text\n",
    "avg5=float(k.replace(\" mb\",\"\").replace(\"Arrow Up\",\"\").replace(\"Arrow Down\",\"\"))\n",
    "print(avg5)\n",
    "\n",
    "#Creating model and extracting AQI and weather training data\n",
    "x2=a0\n",
    "y2=[]\n",
    "df = pandas.read_csv(\"AQI.csv\")\n",
    "x0=json.load(urlopen(\"https://ipinfo.io/\"))['loc'].split(',')\n",
    "# find all table with class-\"twc-table\"\n",
    "x1=float(x0[0])\n",
    "y=float(x0[1])\n",
    "X = df[['Avg1', 'Avg2','Avg3','Avg5']].values\n",
    "#print(X)\n",
    "y1 = df['AQI']\n",
    "#print(y)\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X,y1)\n",
    "x=regr.predict([[9/5*avg1+32,9/5*avg2+32,avg3,avg5*0.02953]])\n",
    "\n",
    "#Printing predicted AQI\n",
    "if x<50:\n",
    "    print('Good')\n",
    "elif x<101:\n",
    "    print('Moderte')\n",
    "elif x<150:\n",
    "    print(\"Unhealthy for Sensitive People\")\n",
    "elif x<200:\n",
    "    print(\"Unhealthy\")\n",
    "elif x<300:\n",
    "    print(\"Hazardous\")\n",
    "else:\n",
    "    print(\"Very Hazardous\")\n",
    " \n",
    "#Converting past wind to vectors to track pollutants\n",
    "for i in a:\n",
    "    if i=='N':\n",
    "        y2.append(0)\n",
    "    elif i=='NW':\n",
    "        y2.append(-45)\n",
    "    elif i=='WNW':\n",
    "        y2.append(-67.5)\n",
    "    elif i=='NNW':\n",
    "        y2.append(-22.5)\n",
    "    elif i=='NE':\n",
    "        y2.append(45)\n",
    "    elif i=='ENE':\n",
    "        y2.append(67.5)\n",
    "    elif i=='NNE':\n",
    "        y2.append(22.5)\n",
    "    elif i=='S':\n",
    "        y2.append(180)\n",
    "    elif i=='SW':\n",
    "        y2.append(225)\n",
    "    elif i=='WSW':\n",
    "        y2.append(237.5)\n",
    "    elif i=='SSW':\n",
    "        y2.append(202.5)\n",
    "    elif i=='SE':\n",
    "        y2.append(135)\n",
    "    elif i=='ESE':\n",
    "        y2.append(112.5)\n",
    "    elif i=='SSE':\n",
    "        y2.append(157.5)\n",
    "    elif i=='W':\n",
    "        y2.append(-90)\n",
    "    elif i==\"E\":\n",
    "        y2.append(90)\n",
    "#Converting\n",
    "for i in range(len(y2)):\n",
    "    y2[i]=y2[i]*math.pi/180\n",
    "for i in range(len(x2)):\n",
    "    x1=x1-(y2[i]*math.cos(x2[i]))*1/54.6\n",
    "    y=y-(y2[i]*math.sin(x2[i]))*1/54.6\n",
    "    \n",
    "#Finding distance from pollution center\n",
    "A1=[]\n",
    "for i in industry_coords:\n",
    "    A1.append((((i[1]-x1)**2+(i[2]-y)**2)**(1/2))*1/54.6)\n",
    "A2=A1\n",
    "A2.sort()\n",
    "\n",
    "#Finding current AQI and comparing to forecasted API\n",
    "blog=soup.findAll('text',attrs={\"data-testid\":\"DonutChartValue\"})\n",
    "i=0\n",
    "for title in blog:\n",
    "    k=title.text\n",
    "    if(i>=1):\n",
    "        break\n",
    "    i=i+1\n",
    "AQI=float(k)\n",
    "print(AQI)\n",
    "print(x[0])\n",
    "\n",
    "#Printing possible sources from our calculated coordinates and deciding penalty by comparing AQI\n",
    "if((AQI-x[0])>50):\n",
    "    print(\"Pollution coordinates:\")\n",
    "    print(\"%.4f\"%x1)\n",
    "    print(\"%.4f\"%y)\n",
    "    print(\"Most probable pollution sources in descending order of possibility:\")\n",
    "    for i in A2:\n",
    "        print(industry_coords_copy[A1.index(i)][0])\n",
    "        A1[A1.index(i)]=0\n",
    "    print(\"Penalty as percentage of revenue:\")\n",
    "    print((AQI-x[0])/x[0]*100)\n",
    "else:\n",
    "    print(\"No penalty required\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bc2c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32d94acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required libraries\n",
    "import json\n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55776dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_coords=[['A',34,-84],['A1',0,0],['A-1',34,-84]]\n",
    "industry_coords_copy=industry_coords\n",
    "a=[]\n",
    "a0=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f63c86f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WNW 17 km/h\n",
      "WNW 19 km/h\n",
      "WNW 19 km/h\n",
      "WNW 20 km/h\n",
      "WNW 18 km/h\n",
      "NW 14 km/h\n",
      "WNW 13 km/h\n",
      "WNW 12 km/h\n",
      "WNW 12 km/h\n",
      "NW 12 km/h\n",
      "WNW 12 km/h\n",
      "WNW 13 km/h\n",
      "WNW 13 km/h\n",
      "WNW 13 km/h\n",
      "WNW 14 km/h\n",
      "WNW 15 km/h\n",
      "WNW 15 km/h\n",
      "WNW 15 km/h\n",
      "WNW 17 km/h\n",
      "WNW 18 km/h\n",
      "WNW 20 km/h\n",
      "WNW 23 km/h\n",
      "WNW 24 km/h\n",
      "WNW 25 km/h\n",
      "WNW 26 km/h\n",
      "WNW 26 km/h\n",
      "WNW 26 km/h\n",
      "WNW 24 km/h\n",
      "WNW 21 km/h\n",
      "WNW 18 km/h\n",
      "WNW 16 km/h\n",
      "WNW 15 km/h\n",
      "WNW 15 km/h\n",
      "WNW 15 km/h\n",
      "WNW 14 km/h\n",
      "WNW 14 km/h\n",
      "WNW 14 km/h\n",
      "WNW 13 km/h\n",
      "WNW 13 km/h\n",
      "WNW 13 km/h\n",
      "WNW 13 km/h\n",
      "WNW 13 km/h\n",
      "WNW 13 km/h\n",
      "WNW 15 km/h\n",
      "WNW 16 km/h\n",
      "WNW 17 km/h\n",
      "WNW 17 km/h\n",
      "WNW 18 km/h\n"
     ]
    }
   ],
   "source": [
    "#Data from web-scraping starts\n",
    "\n",
    "#Finding wind speeds for last day for tracking pollutants\n",
    "page = requests.get('https://weather.com/en-IN/weather/hourbyhour/l/cc76c08b470b5ddd6e64efd9ce8f256542cfed4ba52f6c00a30a74da519cd070')\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "blog=soup.findAll('span',attrs={\"class\":\"Wind--windWrapper--3Ly7c undefined\"})\n",
    "\n",
    "for title in blog:\n",
    "    k=title.text\n",
    "    a.append(k.split(' ')[0])\n",
    "    a0.append(float(k.split(' ')[1]))\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68f663b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.0\n"
     ]
    }
   ],
   "source": [
    "#Finding Humidity\n",
    "page = requests.get('https://weather.com/en-IN/weather/today/l/cc76c08b470b5ddd6e64efd9ce8f256542cfed4ba52f6c00a30a74da519cd070')\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "blog=soup.findAll('span',attrs={\"data-testid\":\"PercentageValue\"})\n",
    "for title in blog:\n",
    "    k=title.text\n",
    "avg3=float(k.replace(\"%\",\"\"))   \n",
    "print(avg3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5550b178",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding Dew Point\n",
    "blog=soup.findAll('span',attrs={\"data-testid\":\"TemperatureValue\"})\n",
    "i=0\n",
    "for title in blog:\n",
    "    k=title.text\n",
    "    if(i>=10):\n",
    "        break\n",
    "    i=i+1\n",
    "avg2=float(k.replace(\"°\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3811b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding avg. temp\n",
    "blog=soup.findAll('span',attrs={\"data-testid\":\"TemperatureValue\"})\n",
    "i=0\n",
    "avg1=0\n",
    "for title in blog:\n",
    "    k=title.text\n",
    "    if(i==1 or i==2):\n",
    "        avg1=avg1+float(k.replace(\"°\",\"\"))\n",
    "    i=i+1\n",
    "avg1=avg1/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30fee3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1017.3\n"
     ]
    }
   ],
   "source": [
    "#Finding Pressure\n",
    "blog=soup.findAll('span',attrs={\"data-testid\":\"PressureValue\"})\n",
    "i=0\n",
    "for title in blog:\n",
    "    k=title.text\n",
    "avg5=float(k.replace(\" mb\",\"\").replace(\"Arrow Up\",\"\").replace(\"Arrow Down\",\"\"))\n",
    "print(avg5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09e30bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating model and extracting AQI and weather training data\n",
    "x2=a0\n",
    "y2=[]\n",
    "df = pandas.read_csv(\"AQI.csv\")\n",
    "x0=json.load(urlopen(\"https://ipinfo.io/\"))['loc'].split(',')\n",
    "# find all table with class-\"twc-table\"\n",
    "x1=float(x0[0])\n",
    "y=float(x0[1])\n",
    "X = df[['Avg1', 'Avg2','Avg3','Avg5']].values\n",
    "#print(X)\n",
    "y1 = df['AQI']\n",
    "#print(y)\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X,y1)\n",
    "x=regr.predict([[9/5*avg1+32,9/5*avg2+32,avg3,avg5*0.02953]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c052c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hazardous\n"
     ]
    }
   ],
   "source": [
    "#Printing predicted AQI\n",
    "if x<50:\n",
    "    print('Good')\n",
    "elif x<101:\n",
    "    print('Moderte')\n",
    "elif x<150:\n",
    "    print(\"Unhealthy for Sensitive People\")\n",
    "elif x<200:\n",
    "    print(\"Unhealthy\")\n",
    "elif x<300:\n",
    "    print(\"Hazardous\")\n",
    "else:\n",
    "    print(\"Very Hazardous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee3df959",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting past wind to vectors to track pollutants\n",
    "for i in a:\n",
    "    if i=='N':\n",
    "        y2.append(0)\n",
    "    elif i=='NW':\n",
    "        y2.append(-45)\n",
    "    elif i=='WNW':\n",
    "        y2.append(-67.5)\n",
    "    elif i=='NNW':\n",
    "        y2.append(-22.5)\n",
    "    elif i=='NE':\n",
    "        y2.append(45)\n",
    "    elif i=='ENE':\n",
    "        y2.append(67.5)\n",
    "    elif i=='NNE':\n",
    "        y2.append(22.5)\n",
    "    elif i=='S':\n",
    "        y2.append(180)\n",
    "    elif i=='SW':\n",
    "        y2.append(225)\n",
    "    elif i=='WSW':\n",
    "        y2.append(237.5)\n",
    "    elif i=='SSW':\n",
    "        y2.append(202.5)\n",
    "    elif i=='SE':\n",
    "        y2.append(135)\n",
    "    elif i=='ESE':\n",
    "        y2.append(112.5)\n",
    "    elif i=='SSE':\n",
    "        y2.append(157.5)\n",
    "    elif i=='W':\n",
    "        y2.append(-90)\n",
    "    elif i==\"E\":\n",
    "        y2.append(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46454356",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting\n",
    "for i in range(len(y2)):\n",
    "    y2[i]=y2[i]*math.pi/180\n",
    "for i in range(len(x2)):\n",
    "    x1=x1-(y2[i]*math.cos(x2[i]))*1/54.6\n",
    "    y=y-(y2[i]*math.sin(x2[i]))*1/54.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48b1f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding distance from pollution center\n",
    "A1=[]\n",
    "for i in industry_coords:\n",
    "    A1.append((((i[1]-x1)**2+(i[2]-y)**2)**(1/2))*1/54.6)\n",
    "A2=A1\n",
    "A2.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edebeb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186.0\n",
      "211.35718980985735\n"
     ]
    }
   ],
   "source": [
    "#Finding current AQI and comparing to forecasted API\n",
    "blog=soup.findAll('text',attrs={\"data-testid\":\"DonutChartValue\"})\n",
    "i=0\n",
    "for title in blog:\n",
    "    k=title.text\n",
    "    if(i>=1):\n",
    "        break\n",
    "    i=i+1\n",
    "AQI=float(k)\n",
    "print(AQI)\n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db956b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing possible sources from our calculated coordinates and deciding penalty by comparing AQI\n",
    "if((AQI-x[0])>50):\n",
    "    print(\"Pollution coordinates:\")\n",
    "    print(\"%.4f\"%x1)\n",
    "    print(\"%.4f\"%y)\n",
    "    print(\"Most probable pollution sources in descending order of possibility:\")\n",
    "    for i in A2:\n",
    "        print(industry_coords_copy[A1.index(i)][0])\n",
    "        A1[A1.index(i)]=0\n",
    "    print(\"Penalty as percentage of revenue:\")\n",
    "    print((AQI-x[0])/x[0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70c66fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d08cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72184e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing model accuracy\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import pandas\n",
    "df = pandas.read_csv(\"AQI.csv\")\n",
    "Y_val=[]\n",
    "x_val=[]\n",
    "x0=0\n",
    "x1=0\n",
    "x2=0\n",
    "x3=0\n",
    "x4=0\n",
    "x5=0\n",
    "X0=0\n",
    "X1=0\n",
    "X2=0\n",
    "X3=0\n",
    "X4=0\n",
    "X5=0\n",
    "for i in range(1000):\n",
    "    X = df[['Avg1','Avg2','Avg3','Avg5']].values\n",
    "    #print(X)\n",
    "    y1 = df['AQI']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y1, test_size=0.2) \n",
    "    #print(y)\n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(X_train, y_train)\n",
    "    X=0\n",
    "    x=0\n",
    "    for y in range(len(X_test)-1):\n",
    "        i=regr.predict([X_test[y]])\n",
    "        if i<50:\n",
    "            if(y_test.values[y]<50):\n",
    "                X=X+1\n",
    "                X0=X0+1\n",
    "            x0=x0+1\n",
    "        elif i<101:\n",
    "            if(y_test.values[y]<101):\n",
    "                X=X+1\n",
    "                X1=X1+1\n",
    "            x1=x1+1\n",
    "        elif i<150:\n",
    "            if(y_test.values[y]<150):\n",
    "                X=X+1\n",
    "                X2=X2+1\n",
    "            x2=x2+1\n",
    "        if i<200:\n",
    "            if(y_test.values[y]<200):\n",
    "                X=X+1\n",
    "                X3=X3+1\n",
    "            x3=x3+1\n",
    "        elif i<300:\n",
    "            if(y_test.values[y]<300):\n",
    "                X=X+1\n",
    "                X4=X4+1\n",
    "            x4=x4+1\n",
    "        else:\n",
    "            X=X+1\n",
    "            X5=X5+1\n",
    "            x5=x5+1\n",
    "    x=len(X_test)\n",
    "    Y_val.append(X/x)\n",
    "    x_val.append(i)\n",
    "import matplotlib.pyplot as plt\n",
    "y=[X3/x3,X4/x4,X5/x5]\n",
    "x=['Level 4', 'Level 5', 'Toxic']\n",
    "plt.bar(x, y)\n",
    "print(sum(Y_val)/len(Y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd7ddbd",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcb56fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eb8fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
